{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yjo-504-lab3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUNj3ETIHqBG",
        "colab_type": "text"
      },
      "source": [
        "#Pre-Question 1 Scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB1JgU8UsCui",
        "colab_type": "code",
        "outputId": "60be2c5a-d33a-4123-d4c2-9c50c5b39bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "#code cell for extracting contents of zipf (data-lab3.zip) to google drive directory\n",
        "\n",
        "#\n",
        "#   SHOULD RUN THIS **ONLY** one time\n",
        "#\n",
        "\n",
        "import zipfile\n",
        "\n",
        "zipf = 'data-lab3.zip'\n",
        "gdrive = '/gdrive/My Drive/colab/'\n",
        "file = gdrive+zipf\n",
        "zi = zipfile.ZipFile(file, 'r')\n",
        "zi.extractall(path='/gdrive/My Drive/colab')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e593146d0717>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgdrive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/gdrive/My Drive/colab/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdrive\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mzipf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mzi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/gdrive/My Drive/colab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/gdrive/My Drive/colab/data-lab3.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iJgZnGsd3cl",
        "colab_type": "code",
        "outputId": "8ce4e7fc-6a59-4c5d-abda-ca8d64b9314c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#code cell for mounting colab to google drive\n",
        "#run this every time need to re-instantiate connection to colab servers\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAU5zq7YFEN6",
        "colab_type": "text"
      },
      "source": [
        "# Question 1: Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5APcAqvJuPx9",
        "colab_type": "text"
      },
      "source": [
        "Approach:\n",
        "\n",
        "\n",
        "1.   Get the path to the parent directory of the dog & cat folders (in this case,  /gdrive/My Drive/colab/data-lab3)\n",
        "2.   Use imutils function paths.list_images to get a list of images, then sort the list\n",
        "3.   Using a reproducable seed, shuffle the order of images\n",
        "4.   For each image..\n",
        "\n",
        "      A.  Read & resize/flatten image to 32x32x3\n",
        "      \n",
        "      B.  Append image to list X (images)\n",
        "      \n",
        "      C. Get label using the path seperator (parent folder name of image)\n",
        "      \n",
        "      D. Append label to list Y (labels)\n",
        "      \n",
        "      E.  If any error occurs during these steps, do not add image to X or label to Y.\n",
        "5.   Print results of read\n",
        "6.   conver X & Y to numpy arrays, then split the testing and training data\n",
        "7.   Using pandas.factorize to categorize 'dog'  & 'cat' from string to integer (0 or 1, respectively)\n",
        "8.   Using keras' to_categoricals to create a one-hot vector for this data.\n",
        "9.   Create & display bar chart using the size of y_train and y_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ml1xdKTFJOK",
        "colab_type": "code",
        "outputId": "dc6e1c76-70fc-40d1-ea8a-cd536f1eb142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "import cv2\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from imutils import paths\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pandas import factorize\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "# base_path = '/gdrive/My Drive/colab/data-lab3'\n",
        "\n",
        "# x=[]   #data\n",
        "# y=[]   #labels\n",
        "\n",
        "# imagePaths = sorted(list(paths.list_images(base_path)))\n",
        "# random.seed(21)\n",
        "# random.shuffle(imagePaths)\n",
        "# n=0\n",
        "# error = 0\n",
        "\n",
        "# for imagePath in imagePaths:\n",
        "#   n+=1\n",
        "#   if (n % 1000 == 0):\n",
        "#     print(str(n)+' images have been loaded')\n",
        "#   try:\n",
        "#     image = cv2.imread(imagePath)\n",
        "#     image = cv2.resize(image, (28,28)).flatten()\n",
        "#     x.append(image)\n",
        "#     label = imagePath.split(os.path.sep)[-2]   #sets label as folder name (cat/dog)\n",
        "#     y.append(label)\n",
        "#   except:\n",
        "#     print(imagePath + ' could not be read. (file size == 0)')\n",
        "#     error+=1\n",
        "\n",
        "    \n",
        "# print('Finished reading files. %d successful, %d were not read.' % (n-error, error))\n",
        "x = np.array(x, dtype='float') / 255.0   #normalizes pixel range from [0,255] to [0,1]\n",
        "y = np.array(y)\n",
        "#using to_categorical for one-hot encoding of categories\n",
        "y = np.where(y_train == 'dog', 0, 1)\n",
        "y_categorical =  to_categorical(y)\n",
        "\n",
        "#maybe remove some dogs from numpy array (np.delete)\n",
        "\n",
        "print(n)\n",
        "print(len(x))\n",
        "\n",
        "(x_train, x_test, y_train, y_test) = train_test_split(x,y_categorical,test_size=0.25, \n",
        "                                    train_size=0.75, random_state=21)\n",
        "\n",
        "\n",
        "#display bar chart to show # of images in both training & testing categories \n",
        "heights = [len(sum(np.where(y_train == 'dog'))), len(sum(np.where(y_test == 'dog')))]\n",
        "heights2 = [len(sum(np.where(y_train == 'cat'))), len(sum(np.where(y_test == 'cat')))]\n",
        "xcoord = ['# training images', '# testing images']\n",
        "plt.bar(x=xcoord, height=heights)\n",
        "plt.bar(x=xcoord, height=heights2, bottom = heights)\n",
        "plt.annotate('dog size='+str(heights[0]), xy=(-0.18,heights[0]/2))\n",
        "plt.annotate('dog size='+str(heights[1]), xy=(0.8,heights[1]/2))\n",
        "plt.annotate('cat size='+str(heights2[0]), xy=(-0.18,heights2[0]*2.8))\n",
        "plt.annotate('cat size='+str(heights2[1]), xy=(0.82,heights2[1]*2.5))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7390\n",
            "7384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b474a1783a69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m (x_train, x_test, y_train, y_test) = train_test_split(x,y_categorical,test_size=0.25, \n\u001b[0;32m---> 51\u001b[0;31m                                     train_size=0.75, random_state=21)\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7384, 5538]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATw42mszFyzP",
        "colab_type": "text"
      },
      "source": [
        "# Question 2: Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAFlVR7hv-N7",
        "colab_type": "text"
      },
      "source": [
        "Approach:\n",
        "\n",
        "\n",
        "1.   Create sequential NN\n",
        "2.   Create input layer (shape 3072, since  32x32x3 = 3072 )\n",
        "3.   Create 3 hidden layers, each with progressively fewer neurons. With Dropouts between them to help regularize predictions.\n",
        "4.   Output layer has an output size of 2 because we have 2 categories\n",
        "5.   create SGD optimizer using keras\n",
        "6.   compile the model using recommended parameters (binary_crossentropy b/c we are only resulting in 2 categories)\n",
        "7.   Fit the model using training & testing data, for 30 epochs.\n",
        "8.   Print summary of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOFKyXfiOFWl",
        "colab_type": "code",
        "outputId": "89facb0f-444f-4b32-d763-e45beb5834d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2519
        }
      },
      "source": [
        "from keras.layers import Dense, Dropout\n",
        "import keras\n",
        "\n",
        "\n",
        "#create neural network\n",
        "model = keras.Sequential()\n",
        "#input shape of 2352 because images are flattened to 28x28x3 = 2352 pixels\n",
        "model.add(Dense(1024, input_shape=(2352,), activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "#3 hidden layers\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(256, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "#output shape of 2 because we have 2 categories, cat or dog.\n",
        "model.add(Dense(len(np.unique(y_train_label)), activation='softmax'))\n",
        "\n",
        "EPOCHS = 60\n",
        "#small learning rate is better for computer vision\n",
        "INIT_LR = 0.001\n",
        "\n",
        "#compile model using compile from keras.\n",
        "#can use a for loop for different SGD values to see which works best\n",
        "sgd = keras.optimizers.SGD(lr=INIT_LR)\n",
        "#also try Adam\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#use fit from keras to train model. Pass in training data and \n",
        "#testing data seperately, & choose values for inputs (like epochs)\n",
        "\n",
        "#class weights since there are more dog images than cat images\n",
        "class_weight = {0: 1, 1: 2.05}\n",
        "\n",
        "M = model.fit(x_train, y_train, class_weight=class_weight, validation_data=(x_test, y_test), epochs=EPOCHS, batch_size=32)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5538 samples, validate on 1846 samples\n",
            "Epoch 1/60\n",
            "5538/5538 [==============================] - 8s 1ms/step - loss: 0.9815 - acc: 0.5390 - val_loss: 0.6879 - val_acc: 0.6641\n",
            "Epoch 2/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9733 - acc: 0.5052 - val_loss: 0.6774 - val_acc: 0.6641\n",
            "Epoch 3/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9747 - acc: 0.5159 - val_loss: 0.6851 - val_acc: 0.6641\n",
            "Epoch 4/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9828 - acc: 0.5007 - val_loss: 0.6804 - val_acc: 0.6641\n",
            "Epoch 5/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9767 - acc: 0.5079 - val_loss: 0.6889 - val_acc: 0.6641\n",
            "Epoch 6/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9732 - acc: 0.5058 - val_loss: 0.6948 - val_acc: 0.3359\n",
            "Epoch 7/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9657 - acc: 0.5103 - val_loss: 0.6947 - val_acc: 0.3359\n",
            "Epoch 8/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9700 - acc: 0.5007 - val_loss: 0.6832 - val_acc: 0.6641\n",
            "Epoch 9/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9681 - acc: 0.5081 - val_loss: 0.6835 - val_acc: 0.6641\n",
            "Epoch 10/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9519 - acc: 0.5258 - val_loss: 0.6898 - val_acc: 0.6641\n",
            "Epoch 11/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9643 - acc: 0.5083 - val_loss: 0.6850 - val_acc: 0.6641\n",
            "Epoch 12/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9586 - acc: 0.5206 - val_loss: 0.6816 - val_acc: 0.6641\n",
            "Epoch 13/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9688 - acc: 0.5038 - val_loss: 0.6800 - val_acc: 0.6641\n",
            "Epoch 14/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9608 - acc: 0.5132 - val_loss: 0.6983 - val_acc: 0.3359\n",
            "Epoch 15/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9574 - acc: 0.5172 - val_loss: 0.7041 - val_acc: 0.3359\n",
            "Epoch 16/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9581 - acc: 0.5134 - val_loss: 0.7006 - val_acc: 0.3359\n",
            "Epoch 17/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9665 - acc: 0.4953 - val_loss: 0.6881 - val_acc: 0.6641\n",
            "Epoch 18/60\n",
            "5538/5538 [==============================] - 6s 1ms/step - loss: 0.9524 - acc: 0.5146 - val_loss: 0.6909 - val_acc: 0.6641\n",
            "Epoch 19/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9533 - acc: 0.5199 - val_loss: 0.6887 - val_acc: 0.6641\n",
            "Epoch 20/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9532 - acc: 0.5098 - val_loss: 0.6960 - val_acc: 0.3359\n",
            "Epoch 21/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9531 - acc: 0.5172 - val_loss: 0.6900 - val_acc: 0.6641\n",
            "Epoch 22/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9440 - acc: 0.5312 - val_loss: 0.6791 - val_acc: 0.6641\n",
            "Epoch 23/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9583 - acc: 0.5184 - val_loss: 0.7027 - val_acc: 0.3359\n",
            "Epoch 24/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9487 - acc: 0.5034 - val_loss: 0.6743 - val_acc: 0.6641\n",
            "Epoch 25/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9565 - acc: 0.5172 - val_loss: 0.6953 - val_acc: 0.3359\n",
            "Epoch 26/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9514 - acc: 0.5036 - val_loss: 0.6795 - val_acc: 0.6641\n",
            "Epoch 27/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9564 - acc: 0.5070 - val_loss: 0.6859 - val_acc: 0.6641\n",
            "Epoch 28/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9587 - acc: 0.4955 - val_loss: 0.6878 - val_acc: 0.6641\n",
            "Epoch 29/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9479 - acc: 0.5258 - val_loss: 0.6936 - val_acc: 0.3559\n",
            "Epoch 30/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9503 - acc: 0.5007 - val_loss: 0.6803 - val_acc: 0.6641\n",
            "Epoch 31/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9450 - acc: 0.5255 - val_loss: 0.6853 - val_acc: 0.6641\n",
            "Epoch 32/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9507 - acc: 0.5152 - val_loss: 0.6949 - val_acc: 0.3359\n",
            "Epoch 33/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9467 - acc: 0.5108 - val_loss: 0.7021 - val_acc: 0.3359\n",
            "Epoch 34/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9440 - acc: 0.5090 - val_loss: 0.6854 - val_acc: 0.6641\n",
            "Epoch 35/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9459 - acc: 0.5294 - val_loss: 0.6922 - val_acc: 0.6641\n",
            "Epoch 36/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9497 - acc: 0.5013 - val_loss: 0.6773 - val_acc: 0.6641\n",
            "Epoch 37/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9451 - acc: 0.5200 - val_loss: 0.6819 - val_acc: 0.6641\n",
            "Epoch 38/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9417 - acc: 0.5200 - val_loss: 0.6931 - val_acc: 0.5173\n",
            "Epoch 39/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9407 - acc: 0.5190 - val_loss: 0.6824 - val_acc: 0.6641\n",
            "Epoch 40/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9479 - acc: 0.5173 - val_loss: 0.6825 - val_acc: 0.6641\n",
            "Epoch 41/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9437 - acc: 0.5251 - val_loss: 0.6880 - val_acc: 0.6641\n",
            "Epoch 42/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9440 - acc: 0.5114 - val_loss: 0.6787 - val_acc: 0.6641\n",
            "Epoch 43/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9406 - acc: 0.5325 - val_loss: 0.6835 - val_acc: 0.6641\n",
            "Epoch 44/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9428 - acc: 0.5123 - val_loss: 0.6835 - val_acc: 0.6641\n",
            "Epoch 45/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9407 - acc: 0.5246 - val_loss: 0.6831 - val_acc: 0.6641\n",
            "Epoch 46/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9412 - acc: 0.5204 - val_loss: 0.7007 - val_acc: 0.3359\n",
            "Epoch 47/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9492 - acc: 0.4975 - val_loss: 0.6900 - val_acc: 0.6641\n",
            "Epoch 48/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9388 - acc: 0.5195 - val_loss: 0.6882 - val_acc: 0.6641\n",
            "Epoch 49/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9424 - acc: 0.5153 - val_loss: 0.6999 - val_acc: 0.3359\n",
            "Epoch 50/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9428 - acc: 0.5005 - val_loss: 0.6851 - val_acc: 0.6641\n",
            "Epoch 51/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9369 - acc: 0.5282 - val_loss: 0.6857 - val_acc: 0.6641\n",
            "Epoch 52/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9431 - acc: 0.5088 - val_loss: 0.6895 - val_acc: 0.6641\n",
            "Epoch 53/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9402 - acc: 0.5153 - val_loss: 0.6801 - val_acc: 0.6641\n",
            "Epoch 54/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9383 - acc: 0.5285 - val_loss: 0.6945 - val_acc: 0.3359\n",
            "Epoch 55/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9389 - acc: 0.5103 - val_loss: 0.6869 - val_acc: 0.6641\n",
            "Epoch 56/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9434 - acc: 0.5114 - val_loss: 0.6977 - val_acc: 0.3359\n",
            "Epoch 57/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9421 - acc: 0.5094 - val_loss: 0.6927 - val_acc: 0.6560\n",
            "Epoch 58/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9357 - acc: 0.5213 - val_loss: 0.6805 - val_acc: 0.6641\n",
            "Epoch 59/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9432 - acc: 0.5170 - val_loss: 0.6887 - val_acc: 0.6641\n",
            "Epoch 60/60\n",
            "5538/5538 [==============================] - 7s 1ms/step - loss: 0.9389 - acc: 0.5218 - val_loss: 0.6876 - val_acc: 0.6641\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 1024)              2409472   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 3,098,754\n",
            "Trainable params: 3,098,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPb9WRf-F2xP",
        "colab_type": "text"
      },
      "source": [
        "# Question 3: Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9I3KLUHxJ6c",
        "colab_type": "text"
      },
      "source": [
        " 1. get a predictions vector by passing in our testing data\n",
        " 2. compare prediction data against our testing data using scikit-learn's classification report\n",
        " 3. get false positive & false negative rates using scikit-learn's roc_curve method. (using our testing data labels as 'y_true')\n",
        " 4. Visualize ROC_CURVE results using matplotlib   #NOTE: my ROC curve is TERRIBLE!! haha\n",
        " \n",
        " NOTE: my model predicts dog 100% of the time since it has a higher confidence in the dog label for every datapoint.\n",
        " I have little idea why it isn't learning from its previous mistakes. Most likely related to number of samples for each category. I tried to offset this using class_weights during model.fit, but it didn't help as much as expected.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJXhTXkQKvYM",
        "colab_type": "code",
        "outputId": "183e44bb-ac68-4cfc-e682-0cb2b0a76d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "#test model by feeding testing dataset (images only)\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "#compare returned predictions to the known labels using classification_report\n",
        "\n",
        "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=['dog', 'cat']))\n",
        "\n",
        "y_true = y_test.argmax(axis=1)\n",
        "y_score = predictions[:,0]\n",
        "#fpr: Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i].\n",
        "#tpr: Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
        "#threshes: Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1.\n",
        "fpr, tpr, threshes = roc_curve(y_true, y_score)\n",
        "\n",
        "\n",
        "#viz results by displaying ROC curve - a probability curve plotting the true \n",
        "  #positive rate against the false positive rate.\n",
        "  #put FPR on x-axis and TPR on y-axis.\n",
        "  #use roc_curve from scikit-learn\n",
        "  \n",
        "  \n",
        "  \n",
        "plt.plot(fpr, tpr, label='ROC curve')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
        "plt.ylabel('True Positive Rate or (Sensitivity)')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f3a6e59e99ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#test model by feeding testing dataset (images only)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#compare returned predictions to the known labels using classification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}